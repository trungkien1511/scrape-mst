import re
import time
import requests
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os

# ----------------------------
# C·∫•u h√¨nh
# ----------------------------
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}
BASE_URL = "https://masothue.com"
TARGET_URL = "https://masothue.com/tra-cuu-ma-so-thue-theo-tinh/da-nang-35"
SHEET_URL = "https://docs.google.com/spreadsheets/d/1h_9C60cqcwOhuWS1815gIWdpYmEDjr-_Qu9COQrL7No/edit#gid=0"
SHEET_NAME = "Sheet1"

# ----------------------------
# 1. C√†o danh s√°ch doanh nghi·ªáp
# ----------------------------
def parse_list_page(html: str):
    soup = BeautifulSoup(html, "lxml")
    results = []
    for block in soup.select("div.tax-listing div[data-prefetch]"):
        h3a = block.select_one("h3 > a")
        company_name = h3a.get_text(strip=True) if h3a else ""
        tax_code = ""
        info_div = block.find("div")
        if info_div:
            for a in info_div.select("a[title]"):
                m = re.search(r"\b(\d{8,15})\b", a.get_text(strip=True))
                if m:
                    tax_code = m.group(1)
                    break
        path = h3a["href"] if h3a and h3a.has_attr("href") else None
        if company_name and tax_code and path:
            results.append({"name": company_name, "tax_code": tax_code, "link": path})
    return results

# ----------------------------
# 2. C√†o chi ti·∫øt c√¥ng ty
# ----------------------------
def fetch_company_details(path: str, delay: float = 1.5) -> dict:
    url = BASE_URL + path
    resp = requests.get(url, headers=HEADERS, timeout=20)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "lxml")

    # --- l·∫•y s·ªë ƒëi·ªán tho·∫°i ---
    phone_td = soup.select_one("td[itemprop='telephone'] span.copy")
    phone = phone_td.get_text(strip=True) if phone_td else ""

    # --- l·∫•y ng√†y c·∫≠p nh·∫≠t MST ---
    last_update = ""
    update_td = soup.find("td", colspan="2")  # <td colspan="2"> ch·ª©a ng√†y c·∫≠p nh·∫≠t
    if update_td and "C·∫≠p nh·∫≠t m√£ s·ªë thu·∫ø" in update_td.get_text():
        em_tag = update_td.find("em")
        if em_tag:
            last_update = em_tag.get_text(strip=True)

    # --- l·∫•y ng∆∞·ªùi ƒë·∫°i di·ªán ---
    representative = ""
    rep_tr = soup.find("tr", {"itemprop": "alumni"})
    if rep_tr:
        rep_span = rep_tr.find("span", {"itemprop": "name"})
        if rep_span:
            representative = rep_span.get_text(strip=True)

    time.sleep(delay)  # tr√°nh b·ªã ch·∫∑n
    return {
        "phone": phone,
        "last_update": last_update,
        "representative": representative
    }

# ----------------------------
# 3. L∆∞u Google Sheet
# ----------------------------
def save_to_google_sheet(data, sheet_url, sheet_name="Sheet1"):
    scope = ["https://spreadsheets.google.com/feeds", 
             "https://www.googleapis.com/auth/drive"]
    creds_dict = json.loads(os.environ["GOOGLE_CREDENTIALS"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_url(sheet_url).worksheet(sheet_name)
    sheet.clear()
    sheet.append_row(["T√™n doanh nghi·ªáp", "Ng∆∞·ªùi ƒë·∫°i di·ªán", "M√£ s·ªë thu·∫ø", "S·ªë ƒëi·ªán tho·∫°i", "Ng√†y c·∫≠p nh·∫≠t MST"])
    for row in data:
        sheet.append_row([
            row["name"], 
            row.get("representative", ""),
            row["tax_code"], 
            row.get("phone", ""), 
            row.get("last_update", "")
        ])
    print("‚úî ƒê√£ l∆∞u d·ªØ li·ªáu v√†o Google Sheet!")

# ----------------------------
# 4. Main
# ----------------------------
if __name__ == "__main__":
    print("üîé ƒêang t·∫£i danh s√°ch c√¥ng ty...")
    resp = requests.get(TARGET_URL, headers=HEADERS, timeout=20)
    resp.raise_for_status()
    companies = parse_list_page(resp.text)
    print(f"üëâ T√¨m th·∫•y {len(companies)} c√¥ng ty.")

    for comp in companies:
        try:
            details = fetch_company_details(comp["link"])
            comp["phone"] = details["phone"]
            comp["last_update"] = details["last_update"]
            comp["representative"] = details["representative"]
            print(f"{comp['tax_code']} | {comp['name']} | {comp['representative']} | {comp['phone']} | {comp['last_update']}")
        except Exception as e:
            print(f"‚ö† L·ªói l·∫•y chi ti·∫øt {comp['tax_code']}: {e}")
            comp["phone"] = ""
            comp["last_update"] = ""
            comp["representative"] = ""

    save_to_google_sheet(companies, SHEET_URL, SHEET_NAME)
